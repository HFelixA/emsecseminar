%
% Sample conclusion of your thesis
%

\chapter{Flush+Reload Cache Attack on Bliss}
\label{bliss}

\section{Gaussian Sampling} %Eventuell zur Theorie

\subsection{CDT Sampling}
Using the cumulative distribution function in the sampler, we build a large table, in which we approximate the probabilities $p_y=\mathbb{P}[x \le y| x \leftarrow D_\sigma ]$ with $\lambda$ Bits of precision. At sampling time, we generate a uniformly random $r \in [0,1)$ and perform a binary search in the table to locate $y \in [-r\sigma, r\sigma]$, so $r \in [p_{y-1}, p_y)$. If restricted to the non-negative part $[o, r\sigma]$, the probabilities are $p^*_y = \mathbb{P}[|x| \le y| x \leftarrow D_\sigma]$, sampling is still $r \in [0,1)$, but $y \in [0, r \sigma]$ is located. 

The binary search in this sampling method can take some time, so one can speed it up by using an additional \textit{guide table I}. This table stores for example 256 entries consisting of intervalls $I[u] = (a_u, b_u), u \in \{0,...255\}$ such that $p^*_{a_{u}} \le u/256$ and $p^*_{b_{u}} \ge (u+1)/256$. At sampling time, the first byte of $r$ is then used to select the corresponding $I[u]$, which leads to a smaller interval to binary search. $r$ is effectively picked byte-by-byte using the guide table approach. Algorithm \ref{algcdt} summarizes the guide table approach.
 \begin{algorithm}
 	\caption{CDT Sampling With Guide Table}
 	\label{algcdt}
 	\begin{algorithmic}[1]
 		\Require{ Big table $T[y]$ containing values $p^*_y$ of the cumulative distribution function of the discrete Gaussian distribution (using only non-negative values), omitting the first byte. Samll table $I$  consisting of the 256 intervals.}
 		\Ensure{Value $y \in [-r\sigma, r\sigma]$, sampled with probability according to $D_\sigma$}
 		\State{pick a random byte $r$}
 		\State{Let $(I_{min}, I_{max}) = (a_r, b_r)$ be the left and right bounds of interval $I[r]$}
 		\If{$I_{max}-I_{min} = 1$}
	 		\State{generate a random sign bit $b \in \{0,1\}$}
	 		\State
	 		\Return {$y=(-1)^bI_{min}$}
	 	\EndIf
	 	\State{Let $i=1$ denote the index of the byte to look at}
	 	\State{Pick a new random byte r}
	 	\While{$1$}
			\State{$I_z = \lfloor \frac{I_{min}+I_{max}}{2}\rfloor$} 
			\If{$r > (i$th byte of $T[I_z])$}
				\State{$I_{min} = I_z$}
			\ElsIf{$r < (i$th byte of $T[I_z])$}
				\State{$I_{max} = I_z$}
			\ElsIf{$I_{max}-I_{min} = 1$}
				\State{generate a random sign bit $b \in \{0,1\}$}
				\State
				\Return{$y=(-1)^bI_{min}$}
				\Else
				\State{increase $i$ by $1$}
				\State{pick new random byte r}
			\EndIf	
		\EndWhile
 	\end{algorithmic}
 \end{algorithm}
\subsection{Rejection Sampling}
Rejection Sampling basically accepts a sampled uniformly random integer $y \in [-r\sigma, r\sigma]$ with probability $p_\sigma(y)/p_\sigma(\mathbb{Z})$. This is done by sampling a uniformly random value $r \in [0,1)$ and accepting the unformly random $y$ if $r \le p_\sigma(y)$. This procedure can be quite expensive, because $p_\sigma(y)$ has to be calculated to a high precision and even then the rejection rate may be quite high.

The authers of the paper which introduces BLISS (QUELLE) proposed a more efficient rejection sampling algorithm, which will be used in the following chapters.%kann man das so schreiben

This algorithm reduces the amount of rejected samples significantly. It begins with sampling a value $x$ according to the binary discrete Gaussian distribution $D_{\sigma 	_{2}}$ with $\sigma _2 = \frac{1}{2 ln 2}$. Uniformly random bits can be used to do this efficiently. $y = Kx + z, z \in \{0,...,K-1\}$ is then uniformly random sampled and $K = \lfloor\frac{\sigma}{\sigma _2} + 1\rfloor$ is distributed according to the targeted discrete Gaussian distribution $D_\sigma$ by rejecting when $b = \exp (−z(z + 2Kx)/(2σ^2)) = 0$ holds.

This last step still requeres some computing because of the exponential value $b$, but the authors provided a more efficiant algorithm for this, too. %algorithmen einfügen


\section{The FLUSH+RELOAD Attack}
The attack used in PAPER HIER EINFÜGEN is the FLUSH+RELOAD cache attack. This attack abuses the fact, that modern CPUs feature multiple different cache levels, for example L1 cache. This is the fastest and smallest cache level and located closest to the cpu core. The next level, L2 cache, is bigger and slower than L1, L3 is even bigger and slower than L2, etc.

If the CPU has to access a memory address, it looks for the corresponding memory block in higher levels first. If the block is found, a \textit{cache hit}, the data is accessed. But in case of a \textit{cache miss}, it starts to look for the memory block on lower cache levels down to the system memory. If the corresponding block is found in lower levels, the processor \textit{evicts} a cache line in the higher memory and places the found memory line there, to speed up future access on the same memory block.

The higher access times on lower cache levels are exploited by cache timing attacks like the FLUSH+RELOAD attack. The attacker has to use the same memory as the victim to apply this kind of attack. He can monitor the state of the cache and use the timing differences to check which memory blocks are cached and which addresses were accessed by the victim. If done correctly, the attacker can deduce the cache lines of the victims table access, which limits the possible chosen values.


The FLUSH+RELOAD attack abuses the x86\_64 instruction \verb|clflush| to evict a memory block from cache, before the victim executes his algorithm. After the victim is done with his memory access, he measures the time to access the memory block again. If the victim accessed the memory block, the block will be in a fast cache level and the access time will be low. If it was not accessed, the CPU has to load the memory block from a lower cache level and the access will be much slower. The attacker then knows, if the flushed memory block was accessed or not.

\subsection{Attacking CDT Sampling}
The CDT sampling algorithm with an interval table $I$ and a table with actual values $T$ is attackable by the attack described above.

\subsection{Attacking Rejection Sampling}
When rejection sampling is used in the BLISS scheme, the side channel has to decide, if there was a table acces in the $ET$ table. The attack exploits the small size of the $ET$ table, which leaks very precise information about the sampling process.

Depending on the bit $i$ of input $x$, $ET[i]$ is accessed, if $x = 0$, no table look-up is performed. If the attacker detects this, he knows $z=0$ is the sampled value in step ALGORITHMUSSTEP in AlgBLA. In this case the attacker can assume $y \in \{0, \pm K, \pm 2K,...\}$ for usable cache access patterns.

So the attacker knows the coefficients $y_i \in \{0, \pm K, \pm 2K,...\}, i \in \{0,...,n-1\}$ of the noise polynomial y. Because anyone can check if $max|\langle s,c \rangle |\le \kappa < K$ with the public parameters, $y_i$ can be determined completely with the signature vector $z$. With $N$ more signatures $(z_j, c_j), j =1,...N$, the attacker can search for  $y_{ji} \in \{0, \pm K, \pm 2K,...\}$ ($y_{ji}$ means the ith coefficient of$y_j$). If the attacker additionally sees, that $z_{ji} = y_{ji}$, he knows $\langle s, c_{ji} \rangle = 0$. Such vector is a \textit{good vector} for use in the attack and $\zeta _k = c_{ji}$ is saved for later (some known $y_{h}$ will be discarded, if they dont satisfy the necessary requirements). With $n$ of these vectors $\xi _k = c_{ji}; 0 \le i \le n-1, 1 \le j \le N, 1\le k \le n$ a matrix $L \ in \{-1,0,1\}^{nxn}$. The column vectors $\xi_k$ satisfy $sL = 0$ (0 is the all-zero vector) and most likely the only dependency of$\xi_k$ is introduced by s, so s is the only kernel vector. There is no need to randomize this process, because the all-zero vector is used.

ALGORITHMUS   

\section{Attacking the Sampling Algorithms with a Perfect Side Channel}
The paper QUELLE provided experimental results for a perfect side-channel attack using the above attack. This requires the attacker to get every cache line of every table look-up while computing $y$ in CDT and rejection sampling algorithms. The victim is assumed to sign random messages and the signatures are collected by the attacker. Cache lines are 64 byte and each element is 8 byte. 
To fulfill this requirements, the authors of QUELLE modified the \textit{reasearch oriented} C++ implementation published by the BLISS authorsQUELLE. NTL was used for LLL reductions and kernel calculations.
\subsection{Perfect Side Channel Attack on CDT Sampling}
\subsection{Perfect Side Channel Attack on Rejection Sampling}
The perfect side channel tells the attacker, if there was an table loo-up in the table $ET$. The attack explained  in section REFHIER can be applied and requires $m = n$ challenges $c_i$ for the kernel calculation, because no randomization is needed. By checking the cache lines of the small part of the table, the attacker can learn if any element has been accessed in $ET$. Only 100 experiments were performed in this case by the authors of PAPERHIER, because for all parameter sets $p_success = 1.0$ holds.

The expected numbers of signatures needed is:
\begin{equation*}
	\mathbb{E}[N] = ((\frac{1}{p_\sigma(\mathbb{Z})}\sum_{x=-r\sigma}^{r\sigma}p_\sigma(xK))*\mathbb{P}[\langle s_1,c \rangle = 0])^{-1}	
\end{equation*}
with $K= \lfloor \frac{\sigma}{\sigma_2}+1\rfloor$ and tail-cut $r\ge 1$. This number is heavily dependent on the value $\sigma$, because $xK$ is more likely sampled for small $\sigma$

\section{Evaluation}
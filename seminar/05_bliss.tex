%
% Sample conclusion of your thesis
%

\chapter{Flush+Reload Cache Attack on Bliss}
\label{bliss}

\section{Gaussian Sampling} %Eventuell zur Theorie
The Gaussian Sampler is an important part for the security of many lattice based cryptosystems, because it is used to generate important values. This task is essential for the security of the cipher or signature, so the sampler is likely target of an attacker. There are many papers dealing with various ways of discrete gaussian sampling such as \cite{cryptoeprint:2010:088}, but in this chapter we will introduce the two different Gaussian Samplers and side channel attacks as described in \cite{cryptoeprint:2016:300}.
\subsection{CDT Sampling}
Using the cumulative distribution function in the sampler, we build a large table, in which we approximate the probabilities $p_y=\mathbb{P}[x \le y| x \leftarrow D_\sigma ]$ with $\lambda$ Bits of precision. At sampling time, we generate a uniformly random $r \in [0,1)$ and perform a binary search in the table to locate $y \in [-r\sigma, r\sigma]$, so $r \in [p_{y-1}, p_y)$. If restricted to the non-negative part $[0, r\sigma]$, the probabilities are $p^*_y = \mathbb{P}[|x| \le y| x \leftarrow D_\sigma]$, sampling is still $r \in [0,1)$, but $y \in [0, r \sigma]$ is located. 

The binary search in this sampling method can take some time, so one can speed it up by using an additional \textit{guide table I}. This table stores for example 256 entries consisting of intervals $I[u] = (a_u, b_u), u \in \{0,...255\}$ such that $p^*_{a_{u}} \le u/256$ and $p^*_{b_{u}} \ge (u+1)/256$. At sampling time, the first byte of $r$ is then used to select the corresponding $I[u]$, which leads to a smaller interval to binary search. $r$ is effectively picked byte-by-byte using the guide table approach. Algorithm \ref{algcdtwtable} summarizes the guide table approach.
 \begin{algorithm}
 	\caption{CDT Sampling With Guide Table}
 	\label{algcdtwtable}
 	\begin{algorithmic}[1]
 		\Require{ Big table $T[y]$ containing values $p^*_y$ of the cumulative distribution function of the discrete Gaussian distribution (using only non-negative values), omitting the first byte. Samll table $I$  consisting of the 256 intervals.}
 		\Ensure{Value $y \in [-r\sigma, r\sigma]$, sampled with probability according to $D_\sigma$}
 		\State{pick a random byte $r$}
 		\State{Let $(I_{min}, I_{max}) = (a_r, b_r)$ be the left and right bounds of interval $I[r]$}
 		\If{$I_{max}-I_{min} = 1$}
	 		\State{generate a random sign bit $b \in \{0,1\}$}
	 		\State
	 		\Return {$y=(-1)^bI_{min}$}
	 	\EndIf
	 	\State{Let $i=1$ denote the index of the byte to look at}
	 	\State{Pick a new random byte r}
	 	\While{$1$}
			\State{$I_z = \lfloor \frac{I_{min}+I_{max}}{2}\rfloor$} 
			\If{$r > (i$th byte of $T[I_z])$}
				\State{$I_{min} = I_z$}
			\ElsIf{$r < (i$th byte of $T[I_z])$}
				\State{$I_{max} = I_z$}
			\ElsIf{$I_{max}-I_{min} = 1$}
				\State{generate a random sign bit $b \in \{0,1\}$}
				\State
				\Return{$y=(-1)^bI_{min}$}
				\Else
				\State{increase $i$ by $1$}
				\State{pick new random byte r}
			\EndIf	
		\EndWhile
 	\end{algorithmic}
 \end{algorithm}
\subsection{Rejection Sampling}
Rejection Sampling basically accepts a sampled uniformly random integer $y \in [-r\sigma, r\sigma]$ with probability $p_\sigma(y)/p_\sigma(\mathbb{Z})$. This is done by sampling a uniformly random value $r \in [0,1)$ and accepting the unformly random $y$ if $r \le p_\sigma(y)$. This procedure can be quite expensive, because $p_\sigma(y)$ has to be calculated to a high precision and even then the rejection rate may be quite high.

The authers of \cite{bliss} which introduced BLISS proposed a more efficient rejection sampling algorithm, which will be used in the following chapters.%kann man das so schreiben

This algorithm reduces the amount of rejected samples significantly. It begins with sampling a value $x$ according to the binary discrete Gaussian distribution $D_{\sigma 	_{2}}$ with $\sigma _2 = \frac{1}{2 ln 2}$. Uniformly random bits can be used to do this efficiently. $y = Kx + z, z \in \{0,...,K-1\}$ is then uniformly random sampled and $K = \lfloor\frac{\sigma}{\sigma _2} + 1\rfloor$ is distributed according to the targeted discrete Gaussian distribution $D_\sigma$ by rejecting when $b = \exp (−z(z + 2Kx)/(2σ^2)) = 0$ holds.

This last step still requires some computing because of the exponential value $b$, but the authors provided a more efficiant algorithm for this, too. %algorithmen einfügen
 \begin{algorithm}
 	\caption{Sampling from $D^+_{K_{\sigma}}$ for $K\in\mathbb{Z}$}
 	\label{algrjt1}
 	\begin{algorithmic}[1]
 		\Require{Target standard deviation $\sigma$, integer $K = \lfloor \frac{\sigma}{\sigma_2} +1$, where $\sigma_2 = \frac{1}{2ln2}$}
 		\Ensure{Integer $y \in \mathbb{Z}^+$ according to $D^+_{K_{\sigma_{2}}}$}
 		\State{sample $ x \in \mathbb{Z}$ according to $D^+_{K_{\sigma_2}}$}
 		\State{sample $z \in \mathbb{Z}$ unformly in $\{0,...K-1\}$}
 		\State $y \leftarrow Kx + z$
 		\State sample b with probability $exp(-z(z+2Kx)/(2\sigma^2))$
 		\If{$b=0$}
	 		\State
	 		\Return{$y$}
 		\EndIf	
 	\end{algorithmic}
 \end{algorithm}
 \begin{algorithm}
 	\caption{Sampling from $D_{K_{\sigma}}$}
 	\label{algrjt2}
 	\begin{algorithmic}[1]
 		\Ensure{An integer $y \in \mathbb{Z}$ according to $D_{K_{\sigma}}$}
 		\State Sample integer $y \leftarrow D^+_{K_{\sigma}}$ using algorithm \ref{algrjt1}
 		\If{$y = 0$}
	 		\State restart with probability $1/2$
	 	\EndIf
	 	\State generate random bit b and \Return{$(-1)^by$}
 	\end{algorithmic}
 \end{algorithm}
  \begin{algorithm}
  	\caption{Sampling a bit with probability $exp(-x/(2\sigma^2))$ for $x \in [0, 2^\ell=$}
  	\label{algrjt3}
  	\begin{algorithmic}[1]
  	 \Require{$x \in [0,2^\ell)$ an integer in binary form $x = x_{\ell-1}...x_0$. Table $ET$ with precomputed values $ET[i] = exp(-x/(2\sigma^2))$ for $0 \le i \le \ell-1$}
  	 \Ensure{A bit $b$ with probability $exp(-x/(2\sigma^2))$ of being $1$}
  	 \For{$i = \ell -1$}
	  	 \If{$x_i = 1$}
		  	 \State Sample $A_i$ with probability $ET[i]$
		  	 \If {$A_i = 0$} \Return{0}
		  	 \EndIf
		 \EndIf
	 \EndFor
	 \State
	 \Return{1}
  	\end{algorithmic}
  \end{algorithm}

\section{The FLUSH+RELOAD Cache Attack}
The attack used in \cite{cryptoeprint:2016:300} is the FLUSH+RELOAD cache attack. This attack abuses the fact, that modern CPUs feature multiple different cache levels, for example L1 cache. This is the fastest and smallest cache level and located closest to the cpu core. The next level, L2 cache, is bigger and slower than L1, L3 is even bigger and slower than L2, etc.

If the CPU has to access a memory address, it looks for the corresponding memory block in higher levels first. If the block is found, a \textit{cache hit}, the data is accessed. But in case of a \textit{cache miss}, it starts to look for the memory block on lower cache levels down to the system memory. If the corresponding block is found in lower levels, the processor \textit{evicts} a cache line in the higher memory and places the found memory line there, to speed up future access on the same memory block.

The higher access times on lower cache levels are exploited by cache timing attacks like the FLUSH+RELOAD attack. The attacker has to use the same memory as the victim to apply this kind of attack. He can monitor the state of the cache and use the timing differences to check which memory blocks are cached and which addresses were accessed by the victim. If done correctly, the attacker can deduce the cache lines of the victims table access, which limits the possible chosen values.


The FLUSH+RELOAD attack abuses the x86\_64 instruction \verb|clflush| to evict a memory block from cache, before the victim executes his algorithm. After the victim is done with his memory access, he measures the time to access the memory block again. If the victim accessed the memory block, the block will be in a fast cache level and the access time will be low. If it was not accessed, the CPU has to load the memory block from a lower cache level and the access will be much slower. The attacker then knows, if the flushed memory block was accessed or not.

\subsection{Attacking CDT Sampling}
The CDT sampling algorithm with an interval table $I$ and a table with actual values $T$ like in algorithm \ref{algcdtwtable} can leak information based on cache hits and cache misses.

A cache attack as described above can only yield the cache lines of index $u$ of the interval table and the cache line of index $I_z$ of the look-up in $T$. This leaves a range of values for $|y_i|$, additionally the sign of $y_i$is not stored in the table. But the combination of both table look-ups can yield precise information, too.
Two possible combinations of table accesses are \textit{intersection} and \textit{last-jump}. \\
The intersection cache weakness intersects knowledge about index $u$ in $I$ and the access $T[I_z]$. Sometimes values in the range of intervalls are largly not overlapping with the range of values from $T[I_z]$, so the intersection %schnittmenge?!
narrows down the possible values. If, for example, the sample $|y_i|$ has to be in the set $S_1 = \{0,1,2,3,4,5,6,7,8\}$ according to the cache line $I[u]$, but $T[I_z]$ reveals $|y_i|$ must be in $S_2 = \{8,9,10,11,12,13,14,15\}$, we can learn $|y_i| \in S_1 \cap S_2 = \{7,8\}$.\\
Another abusable weakness is called \textit{last-jump} and can be used if elements of an interval $I[u]$ are spread over two cache lines of $T$. For example interval $I[u] = {5,6,7,8,9}$ is divided over cache-lines $T_1 = \{0,1,2,3,4,5,6,7\}$ and $T_2 = \{8,9,10,11,12,13,14,15\}$. A binary search will start at the value $7$ in the always accessed cache-line $T_1$, but cache-line $T_2$ is only accessed, if $|y_i| \in \{8,9\}$.\\
\cite{cryptoeprint:2016:300} restricted the patterns even more: 
\begin{itemize}
	\item To limit the maximum possible error of $|y_i|$ to at most 1, only the weaknesses are used, in which the number of candidates for $|y_i|$ is 2.
	\item Because adjacent intervals can partially overlap, $I[u] \cap I[v] \neq 0$ for $u = v+1$, for certain parts of $I[u]$, the outcome of the sample is biased.
	The second restriction considers only cache weaknesses for which one of the two candidates is much more likely to be sampled.
	\begin{equation*}
		\mathbb{P}[|y_i| = \gamma_1 | y_i \in \{\gamma_1,\gamma_2\}\subset I[u]] \gg \mathbb{P}[|y_i| = \gamma_2 | y_i \in \{\gamma_1,\gamma_2\}\subset I[u]]	
	\end{equation*}
	Values $\gamma_1$ with $\mathbb{P}[X=\gamma_1 | X \in \{\gamma_1, \gamma_2\}\subset I[u]] = 1-\alpha$ with small $\alpha$ are wanted.
	Together with the first restriction, a matched access pattern is almost always $\gamma_1$.
	\item To learn the sign of $|y_i|$, only cache patterns with $|y_i| > \beta \cdot \mathbb{E}[\langle s,c \rangle ], \beta \ge 1$ are used. By looking at the sign of $z_i$ the sign of $y_i$ can be learned, because 
	\begin{equation*}
	sign(y_i) \neq sign(z_i) \iff \langle s,c \rangle > (y_i+z_i)	
	\end{equation*}
\end{itemize}
Choosing different values $\alpha$ and $\beta$ is flexible, but might lead to no matching access patterns or let other parts fail. The paper described $\alpha \le 0.1$ had at least one usable cache access pattern for every parameter set. $\beta$ was not used in the experiments.

The attack assumes a cache access pattern reveals if $y_i \in \{\gamma_1, \gamma_2\}$ for $i = 0,...,n-1$ of polynomial $y$ and $\mathbb{P}[y_i = \gamma_1] = 1- \alpha$ with small $\alpha$. \\
The victim then has to generate $N$ signatures $(z_j, c_j), j= 1,...,N$, which are collected by the attacker and the corresponding cache information for the noise polynomial $y_i$. When a cache weakness is found, the attacker has to solve the equation 
\begin{equation*}
	z_{ji} = y_{ji} + (-1)^{b_j}\langle s,c_ji \rangle
\end{equation*}
Unknown values are $b_j$ and $s$. Because of restrictions above, if $z_{ji = \gamma_1}$, the attacker adds $\xi_k = c_{ji}$ to a list of good vectors. With enough vectors $\xi_k = c_{ji}; 0 \le i \le n-1, 1 \le j \le N, 1 \le k \le n$ the matrix $L \in \{-1,0,1\}^{n \times n}$ can be formed. The column vectors $\xi_k$ satisfy $sL = v$, where $v$ is a unknown, but short, vector with norm about $\sqrt{\alpha n}$ in the lattice spanned by the rows of $L$. A lattice reduction algorithm, like LLL, can search for $v$ and output a uni-modular matrix $U$ with $UL = L'$. Every row of $U$ (or its rotations) is tested if it is a candidate for $s=f$ by checking against the public key.

Because this last step is not always successful, not only $n$ but $m>n$ vectors $\xi_k$ are collected and a random subset forms the input for LLL.

\begin{algorithm}
	\caption{Cache attack on BLISS with CDT Sampling}
	\label{algcdtattack}
	\begin{algorithmic}[1]
		\Require{Access to cache memory of a victim with a key-pair $(A,S)$. BLISS input parameters $n, \sigma, q, \kappa$ with $\kappa <K$. Access to signature polynomials $(z_1, z_2^\dagger, c)$ produced using $S$. Victim uses CDT sampling with tables $T, I$ for noise polynomial $y$. Cache weakness that allows to determine if coefficient $y_i \in \{\gamma_1,\gamma_2\}$ of $y$, and when this is the case, the value of $y_i$, is biased towards $\gamma_1$}
		\Ensure{Secret key $S$}
		\State{Let $k = 0$ be the number of vectors gained so far and let $M=[]$ be an empty list of vectors}
		\While{$k<m$ (m vectors before randomising LLL)}
		\State{Collect signature $(z_1, z_2^\dagger, c)$ together with cache information for each coefficient $y_i$ of noise polynomial $y$}
		\For{$i=1,...,n$}
		\If{$y_i \in \{\gamma_1, \gamma_2\}$ (according to cache information), and $z_{1i} = \gamma_1$}
		\State{add vector $\xi_k = c_i$ as a column to M and set $k = k + 1$}
		\EndIf
		\EndFor
		\EndWhile
		\While{1}
			\State Choose random subset of n vectors from $M$ and construct matrix $L$ whose columns are those vectors from $M$
			\State Perform LLL basis reduction on L to get $UL = L'$, where $U$ is a uni-modular transformation matrix and $L'$ is LLL reduced.
			\ForAll{$J=1,...,n$}
				\State check if row $u_j$ of U has the same distribution as f and if $(a_1/2)\cdot u_j \bmod 2q$ has the same distribution as $2g+1$. Lastly verify if $a_1 \cdot u_j + a_2 \cdot (a_2/2)\cdot u_j \equiv q \bmod 2q$
				\State
				\Return $S = (u_j, (a_1/2)\cdot u_j \bmod 2q)$ if this is the case
			\EndFor
		\EndWhile
	\end{algorithmic}
\end{algorithm} 
\subsection{Attacking Rejection Sampling} \label{rejection}
When rejection sampling is used in the BLISS signature scheme, the side channel has to decide, if there was a table acces in the $ET$ table. The attack exploits the small size of the $ET$ table, which leaks very precise information about the sampling process.

Depending on the bit $i$ of input $x$, $ET[i]$ is accessed, if $x = 0$, no table look-up is performed. If the attacker detects this, he knows $z=0$ is the sampled value in step 2 in algorithm \ref{algrjt1}. In this case the attacker can assume $y \in \{0, \pm K, \pm 2K,...\}$ for usable cache access patterns.

So the attacker knows the coefficients $y_i \in \{0, \pm K, \pm 2K,...\}, i \in \{0,...,n-1\}$ of the noise polynomial y. Because anyone can check if $max|\langle s,c \rangle |\le \kappa < K$ with the public parameters, $y_i$ can be determined completely with the signature vector $z$. With $N$ more signatures $(z_j, c_j), j =1,...,N$, the attacker can search for  $y_{ji} \in \{0, \pm K, \pm 2K,...\}$ ($y_{ji}$ means the ith coefficient of $y_j$). If the attacker additionally sees, that $z_{ji} = y_{ji}$, he knows $\langle s, c_{ji} \rangle = 0$. Such vector is a \textit{good vector} for use in the attack and $\zeta _k = c_{ji}$ is saved for later (some known $y_{ji}$ will be discarded, if they dont satisfy the necessary requirements). With $n$ of these vectors $\xi _k = c_{ji}; 0 \le i \le n-1, 1 \le j \le N, 1\le k \le n$ a matrix $L \in \{-1,0,1\}^{nxn}$ can be formed. The column vectors $\xi_k$ satisfy $sL = 0$ (0 is the all-zero vector) and most likely the only dependency of $\xi_k$ is introduced by s, so s is the only kernel vector. There is no need to randomize this process, because the all-zero vector is used.

\begin{algorithm}
	\caption{Cache attack on BLISS with Rejection Sampling}
	\label{algrctattack}
	\begin{algorithmic}[1]
		\Require{Access to cache memory of a victim with a key-pair $(A,S)$. BLISS input parameters $n, \sigma, q, \kappa$ with $\kappa <K$. Access to signatures $(z_1, z_2^\dagger, c)$ produced using $S$. Victim uses rejection sampling with small exponential table to sample noise polynomial y}
		\Ensure{Secret key $S$}
		\State{Let $k = 0$ be the number of vectors gained so far and let $M=[]$ be an empty list of vectors}
		\While{$k<n$}
			\State{Collect signature $(z_1, z_2^\dagger, c)$ together with cache information for each coefficient $y_i$ of polynomial $y$}
			\For{$i=1,...,n$}
				\If{$y_i \in \{0, \pm K, \pm 2K, ...\}$ (according to cache information), and $z_{1i} = y_i$}
				\State{add coefficient vector $\xi_k = c_i$ as a column to M and set $k = k + 1$}
				\EndIf
			\EndFor
		\EndWhile
		\State{Form a matrix M from the columns in $M$. Calculate kernel space of M. This gives a matrix $U \in \mathbb{Z}^{\ell \times n}$ such that $UM = 0$ where $0$ is the all-zero matrix.}
		\For{$j = 1,...,\ell$ (assume $\ell = 1$)}
			\State{check if row $u_j$ of U has the same distribution as $f$ and if $(a_1/2)\cdot u_j \bmod 2q$ has the same distribution as $2g+1$. Lastly verify if $a_1\cdot u_j + a_2\cdot(a_2/2)\cdot u_j \equiv q \bmod 2q$}
			\State{}
		\Return{$S = (u_j, (a_1/2)\cdot u_j \bmod 2q)$ if this is the case}
		\EndFor
		\State{Remove a random entry from M, put $k = k - 1$, goto step 2}
	\end{algorithmic}
\end{algorithm}   

\newpage
\section{Attacking Sampling Algorithms with a Perfect Side Channel}
The paper \cite{cryptoeprint:2016:300} provided experimental results for a perfect side-channel attack using the procedure explained. This requires the attacker to get every cache line of every table look-up while computing $y$ in CDT and rejection sampling algorithms. The victim is assumed to sign random messages and the signatures are collected by the attacker. Cache lines are 64 byte and each element is 8 byte. 
To fulfill this requirements, the authors of \cite{cryptoeprint:2016:300} modified the \textit{research oriented} C++ implementation published by the BLISS authors \cite{blisshp}. Tests were performed on a 4.1 GHz AMD FX-8350 Eight-Core CPU. NTL was used for LLL reductions and kernel calculations.
\subsection{Perfect Side Channel Attack on CDT Sampling}
A perfect side channel yields the attacker the values $\lfloor u/8 \rfloor$ and $\lfloor I_z/8 \rfloor$ of the table accesses for $I[u]$ and $T[I_z]$, the full cache line for a specific value. 

Because not every cache line contains a intersection or last-jump weakness, a one-time brute force search over the look-up tables reveals cache lines, which are exploitable, by analyzing the structure and applying the biased restriction $\alpha \le 0.1$

For each BLISS parameter set at least one usable cache weakness can be found, which can be abused. 
The attacker then collects $m$ coefficient vectors $c_j$ and runs LLL up to $t = 2(m-n)+1$ times searching for s. A bigger value $t$ is not likely to have better success probabilities, because the randomly constructed lattices have overlapping base vectors, so the authors of the paper considered a experiment failed after this number of tries. Each experiment (with different parameters and different sizes of $m$) was performed 1000 times to measure the success probability $p_{successs}$, the average number of required signatures $\bar{N}$ to get $m$ usable challenges and the average length of $v$, if one was found.
The expected number of needed signatures is:
\begin{equation*}
\mathbb{E}[N] = \frac{m}{n \cdot \mathbb{P}[CP] \cdot \mathbb{P}[\langle s_q, c \rangle = 0]}
\end{equation*}
where the event CP means a usable cache access pattern for a coordinate of $y$.

\begin{table}[ht!]
	\centering
	
	\begin{tabular}{|l|l|l|l|l|l|l|} 	
		Parameter Set & m & $p_{success}$& $||v||^2_2$&$\bar{N}$&$\mathbb{E}[N]$&Offline Time\\\hline
		\multirow{6}{22mm}{BLISS-0 $n = 256$\\$\sigma=100$\\$ \kappa=12$} & 256 & 0.690 &10 &2537 & 2518 &1.9s\\
		& 257& 0.841 & 10 & 2547 & 2528 & 2.9s\\
		&258&0.886&10&2565&2538&3.5s\\
		&259&0.903&10&2671&2548&4.0s\\
		&260&0.943&10&2580&2558&4.5s\\
		&261&0.943&10&2596&2568&4.6s
 \\\hline
		\multirow{6}{22mm}{BLISS-I $n = 512$\\$\sigma=215$\\$ \kappa=23$} & 512 & 0.655 &29 &441 & 450 &37.6s\\
		& 513& 0.809 & 29 & 442 & 451 & 60.0s\\
		&514&0.881&29&442&452&71.3s\\
		&515&0.925&29&443&453&73.9s\\
		&516&0.950&29&446&454&81.3s\\
		&517&0.961&29&446&455&85.8s
		\\\hline
		\multirow{6}{22mm}{BLISS-II $n = 512$\\$\sigma=107$\\$ \kappa=23$} & 512 & 0.478 &33 &2021 & 2020 &37.5s\\
		&513&0.675 &34&2023&2024&72.1s\\
		&514&0.772&34&2030&2028&95.6s\\
		&515&0.818&35&2033&2032&110.4s\\
		&516&0.870&35&2033&2036&117.5s\\
		&517&0.897&35&2041&2040&122.0s
		\\\hline
		\multirow{6}{22mm}{BLISS-III $n = 512$\\$\sigma=250$\\$ \kappa=30$} 
		&512&0.855&23&945&930&42.2s\\
		&513&0.950&23&946&932&51.6s\\
		&514&0.975&23&951&934&55.9s\\
		&515&0.987&24&954&935&55.9s\\
		&516&0.987&24&952&937&55.8s\\
		&517&0.996&24&957&939&54.4s
		\\\hline
		\multirow{6}{22mm}{BLISS-IV $n = 512$\\$\sigma=271$\\$ \kappa=39$} 
		&512&0.617&35&1206&1189&46.2s\\
		&513&0.817&36&1209&1191&75.3s\\
		&514&0.885&36&1211&1194&88.4s\\
		&515&0.932&36&1215&1196&93.7s\\
		&516&0.947&36&1216&1198&102.4s\\
		&517&0.955&36&1217&1201&104.4s
	\end{tabular}
	\caption{Experimental results of an attack on BLISS with CDT sampling using a perfect side channel and various parameter sets}
	\label{tab:cdtperfect}
\end{table}
We can see from the results in table \ref{tab:cdtperfect}, that the average number of signatures $\bar{N}$ needed to collect m usable columns depends more on the paramter $\sigma$ and not much on $n$, because the number of usable cache weaknesses varies with that value QUELLE. The experimental results show a much better succes probabilty $p_{success}$ for a small increase of $m$, so an attacker can reach probabilities close to $1.0$, if e simply collects enough usable signatures (\cite{cryptoeprint:2016:300} suggests picking $m \simeq 2n$). 


\newpage
\subsection{Perfect Side Channel Attack on Rejection Sampling}
The perfect side channel tells the attacker, if there was an table look-up in the table $ET$. The attack explained  in section \ref{rejection} can be applied and requires $m = n$ challenges $c_i$ for the kernel calculation, because no randomization is needed. By checking the cache lines of the small part of the table, the attacker can learn if any element has been accessed in $ET$. Only 100 experiments were performed  in \cite{cryptoeprint:2016:300}, because for all parameter sets $p_{success} = 1.0$ holds.

The expected numbers of signatures needed is:
\begin{equation*}
	\mathbb{E}[N] = ((\frac{1}{p_\sigma(\mathbb{Z})}\sum_{x=-r\sigma}^{r\sigma}p_\sigma(xK))*\mathbb{P}[\langle s_1,c \rangle = 0])^{-1}	
\end{equation*}
with $K= \lfloor \frac{\sigma}{\sigma_2}+1\rfloor$ and tail-cut $r\ge 1$. The average number $\bar{N}$ of required signatures is heavily dependent on the value $\sigma$, because $xK$ is more likely to be sampled for small $\sigma$. 
\begin{table}[h!]
	\centering
	
\begin{tabular}{|l|l|l|l|l|l|} 	
	Parameter Set & m & $p_{success}$&$\bar{N}$&$\mathbb{E}[N]$&Offline Time\\\hline
	BLISS-0 & 256 & 1.0 &1105 & 1102 &0.8s\\
	BLISS-I&512&1.0&1671 & 1694 & 14.7s \\
	BLISS-II&512 & 1.0 & 824&839 & 14.4s\\
	BLISS-III&512 & 1.0 & 3018 & 2970 & 16.0s\\
	BLISS-IV&512 & 1.0 & 4223 & 4154 & 18.1S\\
\end{tabular}
\caption{Experimental results of an attack on BLISS with rejection sampling using a perfect side channel}
\label{tab:rejectionperfect}
\end{table}
\newpage
\section{Attacking Sampling Algorithms with a Real Side Channel}
The experiments explained above used a perfect side channel to get every memory information needed to perform the attack. In the following the proof of concept implementation using a realistic FLUSH+RELOAD attack from \cite{cryptoeprint:2016:300} will be summarized.
\subsection{Attacking CDT Sampling}
Because of various CPU optimizations, like prefetchers, real world implementations cannot assume to have perfectly aligned cache lines or that every loaded cache line was accessed. The \textit{spatial prefetcher} for example pairs two adjacent lines and loads both, if one is accessed. Because this might lead to false positives, only cache weaknesses spanning two unpaired lines can be exploited. \\
The \verb|clflush| instruction is used to flush the monitored cache lines before every $y_i$ is sampled and the access time is measured afterwards. Compared to a reference loadtime, we can determine if an access happened. For simplicity, only one observed cache weakness was monitored in the experiments.\\
Using an Intel i5-3470 processor, 50 attacks on the last-jump weakness $\{\gamma_1, \gamma_2\} = \{55,56\}$ in BLISS-I were performed an it was possible to recover the private key 46 times. To collect the recommended $m = 2n = 1024$ usable equations, on average $3438$ signatures were needed. Only 5 runs of LLL were performed, still a success rate of $92\%$ shows feasibility of the attack. This might vary with different CPUs, because of different prefetchers.
\subsection{Attacking Rejection Sampling}
Because the attack on rejection sampling only needs to know, if $ET$ was accessed at all and the spatial prefetcher, who will reload odd cache lines if the even ones are accessed, flushing all cache lines and reloading only the even ones, covers the whole table $ET$. Randomization, like in CDT, was needed in this case, because the side channel was not a perfect one and some columns $\langle s, c_i \rangle \neq 0$ in L were likely collected. So again, more than n columns were collected an LLL was used to handle the errors. 
With an Intel i7-5650U again 50 attacks against BLISS-I were performed and 3 out of 6 cache lines were monitored. The private key could be recovered 44 times, while on average 3294 signatures wre needed to collect $m = n +100 = 612$ equations. LLL was performed 5 times, similar to the CDT attack.
\section{Evaluation}
As we can see above, the Gaussian Samplers are vulnerable to side channel attacks and especially the FLUSH+RELOAD cache attack is a strong attack vector. Even in a realistic experiment it was possible to compute the private key in many cases, just by monitoring the CPU cache state before and after the signature. The number of signatures needed was not very high either. Access to the systems scheduler will even reduce this number significantly.

This leads to the conclusion, that even fast and reliable gaussian sampling algorithms should be used with care, because an attacker with some kind of access to the processor can break the cryptosystem, even without access to the signature process itself. Masking is one way to reduce the risk of being successful attacked and even choosing different values for the target discrete gaussian distribution may help to avoid such an attack. 